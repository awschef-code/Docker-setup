#
# Telegraf configuration for Agility Platform JMX monitoring
#
# Global tags can be specified here in key="value" format.
[global_tags]
    category = "agility-platform"
    interval = "$COLLECTOR_INTERVAL"
    item_identifier = "$ITEM_IDENTIFIER"
    host_ip = "$HOST_IP"
    ap_container = "$NODE_ID"

# Configuration for telegraf agent
[agent]
    # Default data collection interval for all inputs
    interval = "$COLLECTOR_INTERVAL"

    # Rounds collection interval to 'interval'
    # ie, if interval="10s" then always collect on :00, :10, :20, etc.
    round_interval = true

    # Telegraf will send metrics to outputs in batches of at most
    # metric_batch_size metrics.
    # This controls the size of writes that Telegraf sends to output plugins.
    metric_batch_size = 1000

    # For failed writes, telegraf will cache metric_buffer_limit metrics for each
    # output, and will flush this buffer on a successful write. Oldest metrics
    # are dropped first when this buffer fills.
    # This buffer only fills when writes fail to output plugin(s).
    metric_buffer_limit = 10000

    # Collection jitter is used to jitter the collection by a random amount.
    # Each plugin will sleep for a random time within jitter before collecting.
    # This can be used to avoid many plugins querying things like sysfs at the
    # same time, which can have a measurable effect on the system.
    collection_jitter = "60s"

    # Default flushing interval for all outputs. You shouldn't set this below
    # interval. Maximum flush_interval will be flush_interval + flush_jitter
    flush_interval = "10s"

    # Jitter the flush interval by a random amount. This is primarily to avoid
    # large write spikes for users running a large number of telegraf instances.
    # ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
    flush_jitter = "0s"

    # By default, precision will be set to the same timestamp order as the
    # collection interval, with the maximum being 1s.
    # Precision will NOT be used for service inputs, such as logparser and statsd.
    # Valid values are "ns", "us" (or "Âµs"), "ms", "s".
    precision = ""

    # Logging configuration:
    # Run telegraf with debug log messages.
    debug = false

    # Run telegraf in quiet mode (error log messages only).
    quiet = true

    # Specify the log file name. The empty string means to log to stderr.
    logfile = "/opt/telegraf/var/log/agility-telegraf.log"
    # Override default hostname, if empty use os.Hostname()
    hostname = ""

    # If set to true, do no set the "host" tag in the telegraf agent.
    omit_hostname = false

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# Configuration for sending measurements to generic UDP socket
[[outputs.socket_writer]]
    address = "udp://localhost:8099"

# also write the data to an influxdb
[[outputs.influxdb]]
    urls = ["http://influxdb:8086"]

    # the target database for metrics (telegraf will create the DB if it does not exist)
    database = "telegraf"

###############################################################################
#                            PROCESSOR PLUGINS                                #
###############################################################################

# Print all metrics that pass through this filter.
# [[processors.printer]]

###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################

# Read JMX metrics through Jolokia - this will consolidate all the metrics into one call
[[inputs.jolokia]]
    # this is the context root used to compose the jolokia url - note, the trailing slash is required
    context = "/jolokia/"

    # change the name to match what the collectd listener expects
    name_override = "GenericJMX"

# list of servers exposing jolokia read service
[[inputs.jolokia.servers]]
    name = "Agility-Platform"
    host = "localhost"
    port = "8080"

#
# list of metrics collected on above servers.  each metric consists in a name, a jmx path and either a pass or
# drop slice attribute.
#
# this collects all heap memory usage metrics
[[inputs.jolokia.metrics]]
    name = "memory-"
    mbean = "java.lang:type=Memory"
    attribute = "HeapMemoryUsage"

# collects thread count metrics
[[inputs.jolokia.metrics]]
    name = "threads-"
    mbean = "java.lang:type=Threading"
    attribute = "ThreadCount,PeakThreadCount,TotalStartedThreadCount"

# collects task queue metrics
[[inputs.jolokia.metrics]]
    name = "task_queue-"
    mbean = "com.servicemesh.agility:name=TaskQueue"
    attribute = "QueueSize,QueueCapacity"

# ping: validate credentials/connectivity to cloud provider
[[inputs.jolokia.metrics]]
    name = "ping-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "PingCount,PingFailures,PingTime"

# sync: used during sync process to synchronize information from the cloud provider
[[inputs.jolokia.metrics]]
    name = "sync-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "SyncCount,SyncFailures,SyncTime"

# credential_create: collects metrics on credential create
[[inputs.jolokia.metrics]]
    name = "credential_create-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "CredentialCreateCount,CredentialCreateFailures,CredentialCreateTime"

# credential_release: collects metrics on credential release
[[inputs.jolokia.metrics]]
    name = "credential_release-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "CredentialReleaseCount,CredentialReleaseFailures,CredentialReleaseTime"

# provision: collects metrics on provisioning
[[inputs.jolokia.metrics]]
    name = "provision-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "ProvisionCount,ProvisionFailures,ProvisionTime"

# start: collects metrics on starting
[[inputs.jolokia.metrics]]
    name = "start-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "StartCount,StartFailures,StartTime"

# stop: collects metrics on stopping
[[inputs.jolokia.metrics]]
    name = "stop-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "StopCount,StopFailures,StopTime"

# release: collects metrics on releasing
[[inputs.jolokia.metrics]]
    name = "release-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "ReleaseCount,ReleaseFailures,ReleaseTime"

# reboot: collects metrics on rebooting
[[inputs.jolokia.metrics]]
    name = "reboot-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "RebootCount,RebootFailures,RebootTime"

# SSH Connection: collects metrics on SSH Connection
[[inputs.jolokia.metrics]]
    name = "ssh-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "SshCount,SshFailures,SshTime"

# storage_create: collects metrics on storage create
[[inputs.jolokia.metrics]]
    name = "storage_create-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "StorageCreateCount,StorageCreateFailures,StorageCreateTime"

# storage_release: collects metrics on storage release
[[inputs.jolokia.metrics]]
    name = "storage_release-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "StorageReleaseCount,StorageReleaseFailures,StorageReleaseTime"

# storage_attach: collects metrics on storage attach
[[inputs.jolokia.metrics]]
    name = "storage_attach-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "StorageAttachCount,StorageAttachFailures,StorageAttachTime"

# storage_detach: collects metrics on storage detach
[[inputs.jolokia.metrics]]
    name = "storage_detach-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "StorageDetachCount,StorageDetachFailures,StorageDetachTime"

# storage_create_from_snapshot: collects metrics on storage create from snapshot
[[inputs.jolokia.metrics]]
    name = "storage_create_from_snapshot-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "StorageCreateFromSnapshotCount,StorageCreateFromSnapshotFailures,StorageCreateFromSnapshotTime"

# snapshot_create: collects metrics on snapshot create
[[inputs.jolokia.metrics]]
    name = "snapshot_create-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "SnapshotCreateCount,SnapshotCreateFailures,SnapshotCreateTime"

# snapshot_update: collects metrics on snapshot update
[[inputs.jolokia.metrics]]
    name = "snapshot_update-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "SnapshotUpdateCount,SnapshotUpdateFailures,SnapshotUpdateTime"

# snapshot_release: collects metrics on snapshot release
[[inputs.jolokia.metrics]]
    name = "snapshot_release-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "SnapshotReleaseCount,SnapshotReleaseFailures,SnapshotReleaseTime"

# snapshot_release_all: collects metrics on snapshot release all
[[inputs.jolokia.metrics]]
    name = "snapshot_release_all-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "SnapshotReleaseAllCount,SnapshotReleaseAllFailures,SnapshotReleaseAllTime"

# snapshot_revert: collects metrics on snapshot revert
[[inputs.jolokia.metrics]]
    name = "snapshot_revert-"
    mbean = "com.servicemesh.agility:type=CloudStats,name=*"
    attribute = "SnapshotRevertCount,SnapshotRevertFailures,SnapshotRevertTime"

#
### TODO - the may be replaced zookeeper plugin; however, is it necessary since zookeeper runs in another container?????
#
# zookeeper: collects metrics on zookeeper
#[[inputs.jolokia.metrics]]
#    name = "zookeeper"
#    mbean = "org.apache.ZookeeperService:name0=StandaloneServer_port-1"
#    attribute = "AvgRequestLatency,OutstandingRequests,PacketsReceived,PacketsSent"

#
### TODO - add karaf metrics
#

# Read metrics about cpu usage
[[inputs.cpu]]
    # Whether to report per-cpu stats or not
    percpu = true

    # Whether to report total system cpu stats or not
    totalcpu = false

    # If true, collect raw CPU time metrics.
    collect_cpu_time = true

    # do not send these fields in the message - collectd DB is only interested in raw time
    fielddrop = ["usage_*", "*_min", "*_max", "time_guest", "time_guest_nice"]

    # Don't collect total cpu values
    [inputs.cpu.tagdrop]
    cpu = ["cpu-total"]

# Read metrics about memory usage
[[inputs.mem]]
    fielddrop = ["*_min", "*_max", "*_percent*", "active", "available", "inactive", "total"]

# Read metrics about disk usage
[[inputs.disk]]
    # by default, telegraf gathers stats for all mount points.  Setting mount points will restrict the stats to the specified list
    fielddrop = ["*_min", "*_max", "*_percent*", "total", "inodes_*"]

[[inputs.system]]
    fielddrop = ["load*", "n_*", "uptime_format"]

[[inputs.net]]
    fielddrop = ["drop_*"]

    # Don't collect for the all interface
    [inputs.net.tagdrop]
    interface = ["all"]
